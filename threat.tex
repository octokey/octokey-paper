\section{Threat model and trade-offs}\label{sec:threat}

In this section, we discuss the assumptions we have made with regard to attackers' capabilities,
some aspects which require careful implementation, and some areas where different concerns need to
be traded off against each other.

\subsection{Malware and untrusted software}

Most authentication schemes in a consumer context are based on the principle that once a user has
authenticated, they have unlimited access to their account: using different credentials for
different actions is considered too inconvenient.\footnote{An exception are some online banking
websites, which require explicit authorization of each payment action, using a hardware token.}

Consequently, once a user has authenticated with a service on a device, the software on that device
can in principle do anything it wants to the user account. That is true no matter which
authentication method is used: if there is malware which can read files, log keystrokes and steal
session cookies, or if an attacker can obtain remote root access to a device, any services in use on
that device can be compromised.

With Octokey, there is the additional risk of the device's private key (for inter-device
communication) and mRSA key fragment being stolen. If the device has a built-in hardware security
module, the actual keys are protected, but malware can nevertheless sign arbitrary authentication
requests, because it is almost indistinguishable from legitimate user software. Thus, if malware is
detected on a device, its keys must immediately be revoked.

In sandboxed environments (e.g. websites in web browsers, apps on some mobile OSes), mutually
untrusting applications are somewhat protected from each other. In this case, there needs to be an
explicit way of passing authentication requests between the Octokey application (which manages the
keys) and the websites and apps that require authentication. This mechanism must be implemented
carefully, ensuring that a website or application can only obtain a signed authentication request
for its own URL, and not some other one.

\subsection{Physical device theft and loss}

We assume that the private key material on a device is protected by a human-to-machine
authentication step, e.g. encrypted with a password. This is not much use against malware, but it
does help against an attacker who physically steals a device (or a backup of a device's filesystem).
In section~\ref{sec:ratelimit} we discussed a technique for strengthening this step against brute
force and dictionary attacks.

If the user has enrolled another device, they can use that device to revoke the stolen device. If
the revocation happens before the human-to-machine authentication is broken, no harm is done. If the
device is not revoked in time, the attacker can sign arbitrary authentication requests, and steal
the key by enrolling another device and pairing it with the stolen device. The risk of key theft can
be mitigated by prompting the user on several devices before enrolling another device (provided that
the user has previously enrolled several devices).

If an attacker steals two devices that are paired with each other, the risk of key theft is much
greater, because the human-to-machine authentication is the only remaining protection: deleting key
fragments from the remote store is not sufficient to prevent the attacker from recovering the key.
This means there is a trade-off between security and reliability: pairing physical devices with each
other provides redundancy in case the remote key fragment store is unavailable, but it increases the
risk of the private key being stolen.

Another risk is that the user may lose access to their services: perhaps an attacker who gains
control of a device uses it to revoke the user's legitimate devices (thus preventing the user from
stopping the attacker); perhaps the user has only enrolled one or two physical devices, and they are
stolen simultaneously; perhaps the user's house burns down and all of their devices are lost. To
allow recovery from such situations, we recommend that users print off their private key and store
it in a safe place.

\subsection{Key fragment store}

The key fragment store is likely to be an attack target. If it is compromised, all users need to
re-pair with a new key fragment store (otherwise the ability to revoke keys is lost). For this
reason, the protocol should allow forced re-pairing within a deadline.

Denial of service attacks on the key fragment store are also likely.

Pair all physical devices with each other? Advantage: redundancy in case remote store has an outage.
Disadvantage: if an attacker steals two paired devices (e.g. taking both your laptop and your
smartphone in a robbery), mRSA revocation is not possible, so the human-to-machine authentication
step is the only remaining protection of the private key.

Does revocation still work if the user has only one device (besides the remote service)?
Need to assume everyone has two physical devices?

Does the remote key fragment store need to authenticate signing requests?

The remote key fragment store sees plaintext URLs and challenges, so it could track a user's
activity. Is this ok? Advantage: allows more granular limiting of abuse, e.g. rate limiting login
attempts on one website without affecting other websites.

The user should print off their entire private key, and store it in a safe place (e.g. bank vault).
This gives them a recovery method in case all of their devices are simultaneously destroyed (house
burns down).

Question: how does Octokey know that a certain website URL is the same service as a certain iOS
bundle ID, which is the same service as an Android app signed with a certain public key?

\subsection{2D barcode interception}\label{sec:barcode-intercept}

In the flow for enrolling a new device (section~\ref{sec:newdevice}), and with delegated login
(section~\ref{sec:delegation}), we proposed displaying a 2D barcode on the screen of one device, and
scanning it with the camera of another. We cannot assume confidentiality of these barcodes: an
attacker may snoop it electromagnetically~\cite{Kuhn05}, or simply point a camera at the victim's
screen.

An attacker can thus connect to the URL in the barcode, and enroll the new device to the attacker's
account, instead of the user's own account as intended. With delegated login, the attacker can get
the user to log in with the attacker's key rather than the user's own key. This does not compromise
the user's key, but if the user logs in to the wrong account and doesn't realize it, they may
inadvertently disclose sensitive information to the attacker.

It is not clear whether this would be a problem in practice. If it is, a mutual authentication step
could be added to the flows for enrolling a new device and for delegated authentication (for
example, verifying a 2D barcode in the other direction). However, this makes the process more
complicated for users, especially when trying to delegate authentication to a device which has no
camera, so the additional verification step should probably be optional.

\subsection{2D barcode phishing}\label{sec:barcode-phishing}

When enrolling a new device or performing delegated authentication, we assume that an attacker
cannot trick a user into scanning a different barcode from the one they intended --- i.e. we assume
that the visual channel between the barcode-displaying and the barcode-scanning device provides
integrity (but not confidentiality). If the attacker is able to manipulate what is displayed on
screen, or somehow insert themselves into that channel, the user has bigger problems.

However, a real risk is that a malicious website or app displays a barcode that originates from an
attacker-controlled device, and tricks the user into scanning that barcode and granting the attacker
unwanted access. In this scenario we must rely on well-written warning messages and user education
to ensure the user really understands what they are doing.

For users who have already set up multiple physical devices, as an additional safeguard against
accidentally pairing with an attacker-controlled device, we can require that enrolling a new device
requires user approval on a quorum (e.g. majority) of existing devices. This does not require
additional cryptographic algorithms, but can simply be implemented as a policy in the Octokey
software.

\subsection{Key rotation}
\subsection{Multiple keypairs per user}
\subsection{Multi-way key splitting}
\subsection{Security levels}

% Sync login history across devices, and compare to login history reported by server, to detect
% use of a stolen key


\subsection{Denial of service}

Prevent denial of service due to rate limiting or due to an attacker revoking a user's active
devices.

In the worst case, if an attacker manages to get the entire private key (e.g. by stealing or
compromising two devices that are paired, and breaking the human-to-machine authentication step),
the user's last resort is to generate a new key and update their accounts on all services, adding
the new public key and removing the old one. Unfortunately, the same key-swapping can be performed
by the attacker to lock out the legitimate user.

Therefore, perhaps changing a user's public key on a service should require an additional hurdle,
e.g. using a recovery key that is only stored on paper but not electronically? Or a key that is
split 3 ways? But that would make key rotation difficult.
